{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receipt OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation of Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install opencv-python numpy pytesseract PaddleOCR easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from paddleocr import PaddleOCR\n",
    "import easyocr\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'images/receipt2.jpeg'\n",
    "image_path = 'images/receipt_image.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path, 0)\n",
    "color = cv2.imread(image_path)\n",
    "\n",
    "hsv = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hue, saturation, value = cv2.split(hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function to Show Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    resized_height = 720\n",
    "    percent = resized_height / len(image)\n",
    "    resized_width = int(percent * len(image[0]))\n",
    "    img = cv2.resize(image,(resized_width,resized_height))\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Receipt from the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.mean(color) < 128:\n",
    "    thresh = cv2.threshold(hue, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "else:\n",
    "    thresh = cv2.threshold(hue, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(thresh, kernel=None, iterations=7)\n",
    "dilated = cv2.dilate(eroded, kernel=None, iterations=15)\n",
    "eroded = cv2.erode(dilated, kernel=None, iterations=100)\n",
    "dilated = cv2.dilate(eroded, kernel=None, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_largest_rectangular_contour(color_image, preprocessed_image):\n",
    "    color_image = color_image.copy()\n",
    "    contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = None\n",
    "    largest_area = 0\n",
    "    largest_approx = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_contour = contour\n",
    "                largest_approx = approx\n",
    "                \n",
    "    if largest_contour is not None:\n",
    "        cv2.drawContours(color_image, [largest_approx], -1, (0, 255, 0), 3)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cv2.rectangle(color_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        return color_image, largest_approx\n",
    "    \n",
    "    return color_image, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, cor = extract_largest_rectangular_contour(color, dilated)\n",
    "show(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = max(cor[0][0][1], cor[3][0][1])\n",
    "bottom = min(cor[1][0][1], cor[2][0][1])\n",
    "left = max(cor[0][0][0], cor[1][0][0])\n",
    "right = min(cor[2][0][0], cor[3][0][0])\n",
    "cropped = image[top:bottom, left:right]\n",
    "show(cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(coords):\n",
    "    pts = coords - [left, top]\n",
    "    pts = pts.reshape(4, 2)\n",
    "    sum_pts = pts.sum(axis=1)\n",
    "    diff_pts = np.diff(pts, axis=1)\n",
    "    \n",
    "    top_left = pts[np.argmin(sum_pts)]\n",
    "    top_right = pts[np.argmin(diff_pts)]\n",
    "    bottom_right = pts[np.argmax(sum_pts)]\n",
    "    bottom_left = pts[np.argmax(diff_pts)]\n",
    "    \n",
    "    return np.array([top_left, top_right, bottom_right, bottom_left])\n",
    "\n",
    "def calculate_size(img, ordered):\n",
    "    width = int(img.shape[1] * 0.8)\n",
    "    aspect_ratio = np.linalg.norm(ordered[0] - ordered[3]) / np.linalg.norm(ordered[0] - ordered[1])\n",
    "    return width, int(width * aspect_ratio)\n",
    "\n",
    "def process_image(img, contour):\n",
    "    ordered = order_points(contour)\n",
    "    img_with_pts = img.copy()\n",
    "    for pt in ordered:\n",
    "        img_with_pts = cv2.circle(img_with_pts, tuple(pt), 10, (255, 255, 255), -1)\n",
    "  \n",
    "    w, h = calculate_size(img, ordered)\n",
    "    \n",
    "    pts1 = np.float32(ordered)\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [w, h], [0, h]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    corrected_img = cv2.warpPerspective(img, matrix, (w, h))\n",
    "    \n",
    "    return img_with_pts, corrected_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, corrected = process_image(cropped, cor)\n",
    "show(corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing for OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharp_masking(image, k=1):\n",
    "    blur = cv2.GaussianBlur(image, (11,11), 0)\n",
    "    return cv2.addWeighted(image, k+1, blur, -k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsharp = unsharp_masking(corrected, 11)\n",
    "show(unsharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.where(unsharp > 64, 255, 0).astype(np.uint8)\n",
    "show(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_inv = cv2.bitwise_not(thresh)\n",
    "show(thresh_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image_save_path = 'output/corrected_image_2.jpg'\n",
    "# cv2.imwrite(image_save_path, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting Image for OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "elong = cv2.dilate(thresh_inv, kernel=np.ones((2,4)), iterations=7)\n",
    "show(elong)\n",
    "\n",
    "elong = cv2.dilate(elong, kernel=np.ones((2,2)), iterations=5)\n",
    "show(elong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = corrected.copy()\n",
    "corr = cv2.cvtColor(corr, cv2.COLOR_GRAY2BGR)\n",
    "bounding = []\n",
    "contours = cv2.findContours(elong, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "for contour in contours:\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    \n",
    "    if w*h < 500:\n",
    "        continue\n",
    "    \n",
    "    bounding.append((x,y,w,h))\n",
    "    corr = cv2.rectangle(corr, (x,y), (x+w, y+h), (0,255,0), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,w,h in bounding:\n",
    "    image_slice = corrected[y:y+h, x:x+w]\n",
    "    image_slice_path = \"output/slices/img_\" + f\"{x}{y}{w}{h}\" + \".jpg\"\n",
    "    cv2.imwrite(image_slice_path, image_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optical Character Recognition (OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(image, option):\n",
    "    text_data = []\n",
    "\n",
    "    if option == 1:\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        sentences = text.split('\\n')\n",
    "        text_data.extend(sentences)\n",
    "    \n",
    "    elif option == 2:\n",
    "        ocr = PaddleOCR(use_angle_cls=True, lang='en')  \n",
    "        result = ocr.ocr(image, cls=True)\n",
    "        for line in result[0]:\n",
    "            text_data.append(line[1][0])\n",
    "    \n",
    "    elif option == 3:\n",
    "        reader = easyocr.Reader(['en'])\n",
    "        result = reader.readtext(image)\n",
    "        for detection in result:\n",
    "            text_data.append(detection[1])\n",
    "            \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCR with full Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread(image_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=ocr(test_img, 1)\n",
    "output_text_path='output/text/pytesseract_text.csv'\n",
    "df = pd.DataFrame(text)\n",
    "df.to_csv(output_text_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/11/09 01:44:25] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='/home/ankur/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='/home/ankur/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, formula=False, formula_algorithm='LaTeXOCR', formula_batch_num=1, formula_char_dict_path=None, formula_model_dir=None, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='en', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv4', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/home/ankur/.local/lib/python3.8/site-packages/paddleocr/ppocr/utils/en_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='/home/ankur/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', recovery=False, recovery_to_markdown=False, return_word_box=False, save_crop_res=False, save_log_path='./log_output/', savefile=False, scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mlu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n",
      "[2024/11/09 01:44:26] ppocr DEBUG: dt_boxes num : 35, elapsed : 0.1704256534576416\n",
      "[2024/11/09 01:44:26] ppocr DEBUG: cls num  : 35, elapsed : 0.08346080780029297\n",
      "[2024/11/09 01:44:28] ppocr DEBUG: rec_res num  : 35, elapsed : 2.0277154445648193\n"
     ]
    }
   ],
   "source": [
    "text=ocr(test_img, 2)\n",
    "output_text_path='output/text/paddle_text.csv'\n",
    "df = pd.DataFrame(text)\n",
    "df.to_csv(output_text_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "text=ocr(test_img, 3)\n",
    "output_text_path='output/text/easy_text.csv'\n",
    "df = pd.DataFrame(text)\n",
    "df.to_csv(output_text_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCR with Segmented Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path='output/slices/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for file_name in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        image = cv2.imread(file_path)\n",
    "        text=ocr(image, 1)\n",
    "        data.extend(text)\n",
    "output_text_path='output/text/pytesseract_segmented_text.csv'\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_text_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for file_name in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        image = cv2.imread(file_path)\n",
    "        text=ocr(image, 1)\n",
    "        data.extend(text)\n",
    "output_text_path='output/text/paddle_segmented_text.csv'\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_text_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for file_name in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        image = cv2.imread(file_path)\n",
    "        text=ocr(image, 1)\n",
    "        data.extend(text)\n",
    "output_text_path='output/text/easy_segmented_text.csv'\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_text_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
