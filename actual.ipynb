{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'images/receipt2.jpeg'\n",
    "image_path = 'images/receipt_image.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path, 0)\n",
    "color = cv2.imread(image_path)\n",
    "\n",
    "hsv = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hue, saturation, value = cv2.split(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    \n",
    "    resized_height = 720\n",
    "    percent = resized_height / len(image)\n",
    "    resized_width = int(percent * len(image[0]))\n",
    "    gray = cv2.resize(image,(resized_width,resized_height))\n",
    "\n",
    "\n",
    "    cv2.imshow('cringe', gray)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.mean(color) < 128:\n",
    "    thresh = cv2.threshold(hue, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "else:\n",
    "    thresh = cv2.threshold(hue, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(thresh, kernel=None, iterations=7)\n",
    "dilated = cv2.dilate(eroded, kernel=None, iterations=15)\n",
    "eroded = cv2.erode(dilated, kernel=None, iterations=100)\n",
    "dilated = cv2.dilate(eroded, kernel=None, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_largest_rectangular_contour(color_image, preprocessed_image):\n",
    "    color_image = color_image.copy()\n",
    "    contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = None\n",
    "    largest_area = 0\n",
    "    largest_approx = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_contour = contour\n",
    "                largest_approx = approx\n",
    "                \n",
    "    if largest_contour is not None:\n",
    "        cv2.drawContours(color_image, [largest_approx], -1, (0, 255, 0), 3)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cv2.rectangle(color_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        return color_image, largest_approx\n",
    "    \n",
    "    return color_image, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, cor = extract_largest_rectangular_contour(color, dilated)\n",
    "show(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = max(cor[0][0][1], cor[3][0][1])\n",
    "bottom = min(cor[1][0][1], cor[2][0][1])\n",
    "left = max(cor[0][0][0], cor[1][0][0])\n",
    "right = min(cor[2][0][0], cor[3][0][0])\n",
    "cropped = image[top:bottom, left:right]\n",
    "show(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(coords):\n",
    "    pts = coords - [left, top]\n",
    "    pts = pts.reshape(4, 2)\n",
    "    sum_pts = pts.sum(axis=1)\n",
    "    diff_pts = np.diff(pts, axis=1)\n",
    "    \n",
    "    top_left = pts[np.argmin(sum_pts)]\n",
    "    top_right = pts[np.argmin(diff_pts)]\n",
    "    bottom_right = pts[np.argmax(sum_pts)]\n",
    "    bottom_left = pts[np.argmax(diff_pts)]\n",
    "    \n",
    "    return np.array([top_left, top_right, bottom_right, bottom_left])\n",
    "\n",
    "def calculate_size(img, ordered):\n",
    "    width = int(img.shape[1] * 0.8)\n",
    "    aspect_ratio = np.linalg.norm(ordered[0] - ordered[3]) / np.linalg.norm(ordered[0] - ordered[1])\n",
    "    return width, int(width * aspect_ratio)\n",
    "\n",
    "def process_image(img, contour):\n",
    "    ordered = order_points(contour)\n",
    "    img_with_pts = img.copy()\n",
    "    for pt in ordered:\n",
    "        img_with_pts = cv2.circle(img_with_pts, tuple(pt), 10, (255, 255, 255), -1)\n",
    "  \n",
    "    w, h = calculate_size(img, ordered)\n",
    "    \n",
    "    pts1 = np.float32(ordered)\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [w, h], [0, h]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    corrected_img = cv2.warpPerspective(img, matrix, (w, h))\n",
    "    \n",
    "    return img_with_pts, corrected_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, corrected = process_image(cropped, cor)\n",
    "show(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharp_masking(image, k=1):\n",
    "    blur = cv2.GaussianBlur(image, (11,11), 0)\n",
    "    return cv2.addWeighted(image, k+1, blur, -k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsharp = unsharp_masking(corrected, 11)\n",
    "show(unsharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.where(unsharp > 64, 255, 0).astype(np.uint8)\n",
    "show(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_mask = cv2.dilate(thresh, kernel=np.ones((3,6)), iterations=1)\n",
    "show(thresh_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_eq = cv2.equalizeHist(np.uint8(np.power(corrected / 255.0, 0.5) * 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.bitwise_and(corrected, corrected, mask=thresh_mask)\n",
    "show(test)\n",
    "show(np.where(test > 100, 0, 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = cv2.adaptiveThreshold(test,255,cv2.CALIB_CB_ADAPTIVE_THRESH,cv2.THRESH_BINARY,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(cv2.erode(test2, kernel=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
