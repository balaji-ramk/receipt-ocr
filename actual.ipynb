{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/receipt_image.jpg', 0)\n",
    "color = cv2.imread('images/receipt_image.jpg')\n",
    "hsv = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hue, saturation, value = cv2.split(hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    \n",
    "    resized_height = 720\n",
    "    percent = resized_height / len(image)\n",
    "    resized_width = int(percent * len(image[0]))\n",
    "    gray = cv2.resize(image,(resized_width,resized_height))\n",
    "\n",
    "    cv2.imshow('cringe', gray)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.threshold(hue, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "show(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(thresh, kernel=None, iterations=7)\n",
    "dilated = cv2.dilate(eroded, kernel=None, iterations=15)\n",
    "eroded = cv2.erode(dilated, kernel=None, iterations=100)\n",
    "dilated = cv2.dilate(eroded, kernel=None, iterations=100)\n",
    "show(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_largest_rectangular_contour(color_image, preprocessed_image):\n",
    "    contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = None\n",
    "    largest_area = 0\n",
    "    largest_approx = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_contour = contour\n",
    "                largest_approx = approx\n",
    "                \n",
    "    if largest_contour is not None:\n",
    "        cv2.drawContours(color_image, [largest_approx], -1, (0, 255, 0), 3)\n",
    "        # x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        # cv2.rectangle(color_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        return color_image, largest_approx\n",
    "    \n",
    "    return color_image, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, cor = extract_largest_rectangular_contour(color, dilated)\n",
    "show(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=cor.reshape((4,2))\n",
    "\n",
    "top = np.min(cor[:, 1])-1\n",
    "bottom = np.max(cor[:, 1])+1\n",
    "left = np.min(cor[:, 0])-1\n",
    "right = np.max(cor[:, 0])+1\n",
    "\n",
    "cropped = image[top:bottom, left:right]\n",
    "show(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(coords):\n",
    "    pts = coords - [left, top]\n",
    "    pts = pts.reshape(4, 2)\n",
    "    sum_pts = pts.sum(axis=1)\n",
    "    diff_pts = np.diff(pts, axis=1)\n",
    "    \n",
    "    top_left = pts[np.argmin(sum_pts)]\n",
    "    top_right = pts[np.argmin(diff_pts)]\n",
    "    bottom_right = pts[np.argmax(sum_pts)]\n",
    "    bottom_left = pts[np.argmax(diff_pts)]\n",
    "    \n",
    "    return np.array([top_left, top_right, bottom_right, bottom_left])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_size(img, ordered):\n",
    "    width = int(img.shape[1] * 0.8)\n",
    "    aspect_ratio = np.linalg.norm(ordered[0] - ordered[3]) / np.linalg.norm(ordered[0] - ordered[1])\n",
    "    return width, int(width * aspect_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img, contour):\n",
    "    ordered = order_points(contour)\n",
    "    img_with_pts = img.copy()\n",
    "    for pt in ordered:\n",
    "        img_with_pts = cv2.circle(img_with_pts, tuple(pt), 10, (255, 255, 255), -1)\n",
    "  \n",
    "    w, h = calculate_size(img, ordered)\n",
    "    \n",
    "    pts1 = np.float32(ordered)\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [w, h], [0, h]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    corrected_img = cv2.warpPerspective(img, matrix, (w, h))\n",
    "    \n",
    "    return img_with_pts, corrected_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_pts, corrected_img = process_image(cropped, cor)\n",
    "show(corrected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh_cropped = cv2.adaptiveThreshold(corrected_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,2)\n",
    "# show(thresh_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# med_blur = cv2.medianBlur(thresh_cropped, 3)\n",
    "# show(med_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(corrected_img, (5, 5), 0)\n",
    "mask=cv2.subtract(corrected_img,blur)\n",
    "sharpened = cv2.addWeighted(corrected_img, 1, mask,0.5, 0)\n",
    "# show(sharpened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_img = cv2.equalizeHist(corrected_img)\n",
    "# show(equalized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "clahe_img = clahe.apply(corrected_img)\n",
    "# show(clahe_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINGER CHIPS 1\n",
      "CHL GHEE RAST BONLESS\n",
      "FLL\n",
      "\n",
      "CHI GHEE ROAST BONLESS\n",
      "HALE\n",
      "\n",
      "CRISPY CORN\n",
      "DRAGON CHT\n",
      "ANIAL RAHA FRY.\n",
      "ANGARA KABAB\n",
      "\n",
      "Food Total\n",
      "\n",
      "TEACHERS 60 HL PET\n",
      "YO LUXURY 30K.\n",
      "\n",
      "BLACK 005 30ML\n",
      "BUDWISER MAGNUM 330ML\n",
      "ROMONOV. VODKA 30HL\n",
      "ADVAN CHIPS\n",
      "\n",
      "WHISKY SOUR\n",
      "\n",
      " \n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(clahe_img)\n",
    "sentences=text.split('\\n')\n",
    "for s in sentences:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
